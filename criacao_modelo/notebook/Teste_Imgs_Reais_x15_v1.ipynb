{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "793b549f",
   "metadata": {},
   "source": [
    "## Objetivo: testar a rede neural treinada com fator upscale igual a 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0795fc",
   "metadata": {},
   "source": [
    "Passo 1: Imports, definições de caminhos, classes e funções utilizadas pelo programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fad1fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 17:06:55.226797: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-01 17:06:55.226834: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Imports necessários\n",
    "import os\n",
    "import PIL\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def constroi_modelo(upscale_factor=15, channels=1):\n",
    "    conv_args = {\n",
    "        \"activation\": \"relu\",\n",
    "        \"kernel_initializer\": \"Orthogonal\",\n",
    "        \"padding\": \"same\",\n",
    "    }\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    x = layers.Conv2D(64, 5, **conv_args)(inputs)\n",
    "    x = layers.Conv2D(64, 3, **conv_args)(x)\n",
    "    x = layers.Conv2D(32, 3, **conv_args)(x)\n",
    "    x = layers.Conv2D(channels * (upscale_factor ** 2), 3, **conv_args)(x)\n",
    "    outputs = tf.nn.depth_to_space(x, upscale_factor)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    loss_fn = keras.losses.MeanSquaredError()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=loss_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def conversor_alta_resolucao(modelo, img):\n",
    "    ycbcr = img.convert(\"YCbCr\")\n",
    "    img_cinza, canal_cb, canal_cr = ycbcr.split()\n",
    "    img_cinza = img_to_array(img_cinza)\n",
    "    img_cinza = img_cinza.astype(\"float32\") / 255.0\n",
    "\n",
    "    entrada = np.expand_dims(img_cinza, axis=0)\n",
    "    saida = modelo.predict(entrada)\n",
    "\n",
    "    saida_img_cinza = saida[0]\n",
    "    saida_img_cinza *= 255.0\n",
    "\n",
    "    saida_img_cinza = saida_img_cinza.clip(0, 255)\n",
    "    saida_img_cinza = saida_img_cinza.reshape(\n",
    "        (np.shape(saida_img_cinza)[0], \n",
    "         np.shape(saida_img_cinza)[1])\n",
    "    )\n",
    "\n",
    "    saida_img_cinza = PIL.Image.fromarray(np.uint8(saida_img_cinza), mode=\"L\")\n",
    "    saida_canal_cb = canal_cb.resize(saida_img_cinza.size, PIL.Image.BICUBIC)\n",
    "    saida_canal_cr = canal_cr.resize(saida_img_cinza.size, PIL.Image.BICUBIC)\n",
    "    img_resultado = PIL.Image.merge(\"YCbCr\", \n",
    "            (saida_img_cinza, saida_canal_cb, saida_canal_cr)).convert(\n",
    "        \"RGB\"\n",
    "    )\n",
    "    return img_resultado\n",
    "\n",
    "\n",
    "def abreImagem(nome):\n",
    "    return PIL.Image.open(nome)\n",
    "\n",
    "\n",
    "def printImagem(modelo, nome):\n",
    "    imgBaixa = abreImagem(nome)\n",
    "    display(imgBaixa)\n",
    "    \n",
    "    imgAlta = conversor_alta_resolucao(modelo, imgBaixa)\n",
    "    display(imgAlta)\n",
    "    \n",
    "    print(f\"Imagem baixa: {imgBaixa.size[0], imgBaixa.size[1]}\")\n",
    "    print(f\"Imagem alta: {imgAlta.size[0], imgAlta.size[1]}\")\n",
    "\n",
    "    \n",
    "# Pasta com os checkpoints\n",
    "PASTA_CHECKPOINT: str = r\"/home/dangelo/dev/TCC/image-resolution/src/criacao_modelo/checkpoint_15x\"\n",
    "ARQUIVO_CHECKPOINT: str = os.path.join(PASTA_CHECKPOINT, \"meu-checkpoint\")\n",
    "PASTA_IMGS: str = r\"/home/dangelo/Downloads/imgs_teste\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cda32b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 1)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, None, None, 64)    1664      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 32)    18464     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 225)   65025     \n",
      "_________________________________________________________________\n",
      "tf.nn.depth_to_space (TFOpLa (None, None, None, 1)     0         \n",
      "=================================================================\n",
      "Total params: 122,081\n",
      "Trainable params: 122,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 17:13:27.161821: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-01 17:13:27.161847: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-01 17:13:27.161869: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dangelo-mint): /proc/driver/nvidia/version does not exist\n",
      "2021-09-01 17:13:27.162086: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Construindo o modelo\n",
    "modelo = constroi_modelo(upscale_factor=15, channels=1)\n",
    "modelo.load_weights(ARQUIVO_CHECKPOINT)\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a41db96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaeb561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo executado! 1 de 96 imagens processadas...\n",
      "Processo executado! 2 de 96 imagens processadas...\n",
      "Processo executado! 3 de 96 imagens processadas...\n",
      "Processo executado! 4 de 96 imagens processadas...\n",
      "Processo executado! 5 de 96 imagens processadas...\n",
      "Processo executado! 6 de 96 imagens processadas...\n",
      "Processo executado! 7 de 96 imagens processadas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 17:42:35.653937: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1323450900 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo executado! 8 de 96 imagens processadas...\n",
      "Processo executado! 9 de 96 imagens processadas...\n",
      "Processo executado! 10 de 96 imagens processadas...\n",
      "Processo executado! 11 de 96 imagens processadas...\n",
      "Processo executado! 12 de 96 imagens processadas...\n",
      "Processo executado! 13 de 96 imagens processadas...\n",
      "Processo executado! 14 de 96 imagens processadas...\n",
      "Processo executado! 15 de 96 imagens processadas...\n",
      "Processo executado! 16 de 96 imagens processadas...\n",
      "Processo executado! 17 de 96 imagens processadas...\n",
      "Processo executado! 18 de 96 imagens processadas...\n",
      "Processo executado! 19 de 96 imagens processadas...\n",
      "Processo executado! 20 de 96 imagens processadas...\n",
      "Processo executado! 21 de 96 imagens processadas...\n",
      "Processo executado! 22 de 96 imagens processadas...\n",
      "Processo executado! 23 de 96 imagens processadas...\n",
      "Processo executado! 24 de 96 imagens processadas...\n",
      "Processo executado! 25 de 96 imagens processadas...\n",
      "Processo executado! 26 de 96 imagens processadas...\n",
      "Processo executado! 27 de 96 imagens processadas...\n",
      "Processo executado! 28 de 96 imagens processadas...\n",
      "Processo executado! 29 de 96 imagens processadas...\n",
      "Processo executado! 30 de 96 imagens processadas...\n",
      "Processo executado! 31 de 96 imagens processadas...\n",
      "Processo executado! 32 de 96 imagens processadas...\n",
      "Processo executado! 33 de 96 imagens processadas...\n"
     ]
    }
   ],
   "source": [
    "lista_imagens = os.listdir(PASTA_IMGS)\n",
    "contador = 0\n",
    "\n",
    "# Mudando o nome das HR para 3x e fazendo com x15\n",
    "for img in lista_imagens:\n",
    "    \n",
    "    caminho_img: str = os.path.join(PASTA_IMGS, img)\n",
    "    \n",
    "    # Se tiver \"hr\" no nome, mudar para \"hr_3x\"\n",
    "    if \"hr\" in caminho_img:\n",
    "        caminho_img_3x: str = caminho_img.replace(\"hr\", \"hr_3x\")\n",
    "        os.rename(src=caminho_img, dst=caminho_img_3x)\n",
    "    \n",
    "    # Se não tiver, quer dizer que será \"lr\". Processar a img\n",
    "    elif \"lr\" in caminho_img:\n",
    "        caminho_img_15x: str = caminho_img.replace(\"lr\", \"hr_15x\")\n",
    "        \n",
    "        img_lr = abreImagem(caminho_img)\n",
    "        img_hr_15x = conversor_alta_resolucao(modelo, img_lr)\n",
    "        \n",
    "        img_hr_15x.save(caminho_img_15x)\n",
    "        \n",
    "    contador += 1\n",
    "    print(f\"Processo executado! {contador} de {len(lista_imagens)} imagens processadas...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e322566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
